#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è YOLO —Ñ–æ—Ä–º–∞—Ç–∞.
–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤ YOLO —Ñ–æ—Ä–º–∞—Ç –∏ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –Ω–∞ train/val/test.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python utils/prepare_dataset.py --input dataset/raw --output dataset --split 0.8 0.15 0.05
"""

import os
import shutil
import argparse
from pathlib import Path
from typing import Tuple, List
import random
import yaml
from tqdm import tqdm


def parse_args():
    parser = argparse.ArgumentParser(description='–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è YOLO')
    parser.add_argument('--input', type=str, required=True, 
                        help='–ü—É—Ç—å –∫ raw –¥–∞—Ç–∞—Å–µ—Ç—É —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏')
    parser.add_argument('--output', type=str, default='dataset',
                        help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: dataset)')
    parser.add_argument('--split', type=float, nargs=3, default=[0.8, 0.15, 0.05],
                        help='–ü—Ä–æ–ø–æ—Ä—Ü–∏–∏ train/val/test (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.8 0.15 0.05)')
    parser.add_argument('--format', type=str, default='yolo', choices=['yolo', 'coco', 'voc'],
                        help='–§–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: yolo)')
    parser.add_argument('--seed', type=int, default=42,
                        help='Random seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏')
    parser.add_argument('--validate', action='store_true',
                        help='–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏')
    return parser.parse_args()


def get_image_files(input_dir: Path) -> List[Path]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    images = []
    
    for ext in image_extensions:
        images.extend(input_dir.glob(f'*{ext}'))
        images.extend(input_dir.glob(f'*{ext.upper()}'))
    
    return sorted(images)


def split_dataset(files: List[Path], split_ratio: Tuple[float, float, float], 
                  seed: int = 42) -> Tuple[List[Path], List[Path], List[Path]]:
    """–†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ train/val/test."""
    random.seed(seed)
    random.shuffle(files)
    
    total = len(files)
    train_ratio, val_ratio, test_ratio = split_ratio
    
    train_end = int(total * train_ratio)
    val_end = train_end + int(total * val_ratio)
    
    train_files = files[:train_end]
    val_files = files[train_end:val_end]
    test_files = files[val_end:]
    
    return train_files, val_files, test_files


def copy_files_with_labels(files: List[Path], input_dir: Path, output_dir: Path, 
                           subset: str, format_type: str = 'yolo'):
    """–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏."""
    img_output = output_dir / 'images' / subset
    label_output = output_dir / 'labels' / subset
    
    img_output.mkdir(parents=True, exist_ok=True)
    label_output.mkdir(parents=True, exist_ok=True)
    
    copied_count = 0
    missing_labels = []
    
    for img_file in tqdm(files, desc=f'–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {subset}'):
        # –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        shutil.copy2(img_file, img_output / img_file.name)
        
        # –ù–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
        label_file = input_dir / f"{img_file.stem}.txt"
        
        if label_file.exists():
            if format_type == 'yolo':
                # YOLO —Ñ–æ—Ä–º–∞—Ç —É–∂–µ –≥–æ—Ç–æ–≤, –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º
                shutil.copy2(label_file, label_output / f"{img_file.stem}.txt")
            else:
                # TODO: –î–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –∏–∑ –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ (COCO, VOC)
                print(f"‚ö†Ô∏è  –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ {format_type} –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞")
                shutil.copy2(label_file, label_output / f"{img_file.stem}.txt")
            
            copied_count += 1
        else:
            missing_labels.append(img_file.name)
    
    if missing_labels:
        print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(missing_labels)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ {subset}")
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤ —Ñ–∞–π–ª
        with open(output_dir / f'missing_labels_{subset}.txt', 'w') as f:
            f.write('\n'.join(missing_labels))
    
    return copied_count, len(missing_labels)


def validate_annotations(dataset_dir: Path) -> dict:
    """–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏."""
    stats = {
        'total_files': 0,
        'valid_files': 0,
        'invalid_files': 0,
        'errors': []
    }
    
    for subset in ['train', 'val', 'test']:
        label_dir = dataset_dir / 'labels' / subset
        if not label_dir.exists():
            continue
        
        label_files = list(label_dir.glob('*.txt'))
        stats['total_files'] += len(label_files)
        
        for label_file in label_files:
            try:
                with open(label_file, 'r') as f:
                    lines = f.readlines()
                
                valid = True
                for line_num, line in enumerate(lines, 1):
                    parts = line.strip().split()
                    if len(parts) != 5:
                        stats['errors'].append(
                            f"{label_file.name}:{line_num} - –ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞—á–µ–Ω–∏–π"
                        )
                        valid = False
                        continue
                    
                    try:
                        class_id = int(parts[0])
                        x_center, y_center, width, height = map(float, parts[1:])
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ (0-1 –¥–ª—è YOLO —Ñ–æ—Ä–º–∞—Ç–∞)
                        if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 
                                0 < width <= 1 and 0 < height <= 1):
                            stats['errors'].append(
                                f"{label_file.name}:{line_num} - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0, 1]"
                            )
                            valid = False
                    except ValueError:
                        stats['errors'].append(
                            f"{label_file.name}:{line_num} - –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"
                        )
                        valid = False
                
                if valid:
                    stats['valid_files'] += 1
                else:
                    stats['invalid_files'] += 1
                    
            except Exception as e:
                stats['errors'].append(f"{label_file.name} - –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {str(e)}")
                stats['invalid_files'] += 1
    
    return stats


def main():
    args = parse_args()
    
    input_dir = Path(args.input)
    output_dir = Path(args.output)
    
    if not input_dir.exists():
        print(f"‚ùå –í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_dir}")
        return
    
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    print(f"üìÅ –í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {input_dir}")
    print(f"üìÇ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
    print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: train={args.split[0]:.1%}, val={args.split[1]:.1%}, test={args.split[2]:.1%}")
    
    # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("\nüîç –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    image_files = get_image_files(input_dir)
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
    
    if len(image_files) == 0:
        print("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    # –†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ train/val/test
    print("\n‚úÇÔ∏è  –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    train_files, val_files, test_files = split_dataset(image_files, args.split, args.seed)
    print(f"   Train: {len(train_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"   Val:   {len(val_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"   Test:  {len(test_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã
    print("\nüìã –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...")
    
    train_copied, train_missing = copy_files_with_labels(
        train_files, input_dir, output_dir, 'train', args.format
    )
    val_copied, val_missing = copy_files_with_labels(
        val_files, input_dir, output_dir, 'val', args.format
    )
    test_copied, test_missing = copy_files_with_labels(
        test_files, input_dir, output_dir, 'test', args.format
    )
    
    print(f"\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω!")
    print(f"   Train: {train_copied} —Ñ–∞–π–ª–æ–≤ (–ø—Ä–æ–ø—É—â–µ–Ω–æ: {train_missing})")
    print(f"   Val:   {val_copied} —Ñ–∞–π–ª–æ–≤ (–ø—Ä–æ–ø—É—â–µ–Ω–æ: {val_missing})")
    print(f"   Test:  {test_copied} —Ñ–∞–π–ª–æ–≤ (–ø—Ä–æ–ø—É—â–µ–Ω–æ: {test_missing})")
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    if args.validate:
        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π...")
        stats = validate_annotations(output_dir)
        print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']}")
        print(f"   –í–∞–ª–∏–¥–Ω—ã—Ö: {stats['valid_files']}")
        print(f"   –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {stats['invalid_files']}")
        
        if stats['errors']:
            print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(stats['errors'])} –æ—à–∏–±–æ–∫:")
            for error in stats['errors'][:10]:  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 10
                print(f"   - {error}")
            if len(stats['errors']) > 10:
                print(f"   ... –∏ –µ—â–µ {len(stats['errors']) - 10} –æ—à–∏–±–æ–∫")
    
    print(f"\n‚ú® –ì–æ—Ç–æ–≤–æ! –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_dir}")


if __name__ == '__main__':
    main()
